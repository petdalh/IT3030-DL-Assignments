globals:
  learning_rate: 0.12
  epochs: 100
  batch_size: 10
  loss_function: cross_entropy

layers:
  - input_size: 1600
    output_size: 256
    activation: relu
    regularizer:
      type: L1
      rate: 0.00005
  - input_size: 256
    output_size: 128
    activation: relu
    regularizer:
      type: L1
      rate: 0.0005
  - input_size: 128
    output_size: 64
    activation: relu
    regularizer:
      type: L1
      rate: 0.0005
  - input_size: 64
    output_size: 32
    activation: relu
    regularizer:
      type: L1
      rate: 0.0005
  - input_size: 32
    output_size: 16
    activation: relu
    regularizer:
      type: L1
      rate: 0.0005
  - input_size: 16
    output_size: 4
    activation: softmax
    regularizer:
      type: L1
      rate: 0.0005

dataset:
  type: image_generator
  params:
    n: 40
    noise: 0.02
    num_images: 3500 # Ensuring at least 100 training cases
    width_range: [10, 20]
    height_range: [10, 20]
    train_ratio: 0.6 # Adjusted to ensure at least 100 training cases
    val_ratio: 0.2
